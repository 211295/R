### 20/03/2024
### Regression models ###
### load packages:
if(!require(ape)){install.packages("ape");library(ape)}
if(!require(paleotree)){install.packages("paleotree");library(paleotree)}
if(!require(nlme)){install.packages("nlme");library(nlme)}
if(!require(caper)){install.packages("caper");library(caper)}

### set working directory load files
setwd("C:/Users/HP/Documents/FELIPE/Estatistica e Programacao/Analise Filogenetica")

### Since we already have time-scaled trees (see time-scaling), let's import them. For example, we can import the "mbl trees" we created with the previous script:
trees <- dget(file = "croc tree, 20 trees, mbl method.txt")

### selecting the first 5 trees only (instead of all 20 trees, for making analyses faster)
five_trees <- trees[1:5]

### load ages (as in time-scale tutorial)
ages <- read.table("croc_ages.txt", header=T, row.names = 1)

### load data (using function "read.table()":
my_data <- read.table("croc_sizes.txt", header=T) # avoid using the word "data"

### This dataset contains crocodylomorph body size data. Instead of estimating total body size, it uses a proxy (the cranial measurement ODCL)
### this measurement was log-transformed prior to being imported into R

### inspecting the 'my_data' object
my_data
class(my_data)
str(my_data) 
### this data has 241 observations (obs), which are the specimens, get the average values for each species

### let's do it using a loop and functions "unique()" and "mean()"
### function "unique()" gets unique names in element "Taxon"
taxon.list <- unique(my_data$Taxon) 
str(taxon.list) # we now know that there are 195 taxa
length(taxon.list)

### now, let's use a loop for getting mean values:
taxon.lengths <- c() 
### must create an empty list, R needs a object to receive the loop
for(i in 1: length(taxon.list)) {taxon.lengths[i] <- mean(my_data[my_data$Taxon==taxon.list[i], "log_odcl"])}
###this part can be a bit confusing, but it gets easy with practice

names(taxon.lengths) <- taxon.list
### uses the list of specimens we created above as the row names of this new list
my_new_data <- taxon.lengths # renaming it back to "my_data"

### inspecting, it should be 195 species!
my_new_data
myhead(my_new_data)
str(my_new_data)
class(my_new_data)
### it is now a 'numeric' object. we might need to convert it back to 'data frame' later...

### now, let's compare the tree with the data
length(my_new_data) # 195 taxa
Ntip(five_trees[[1]]) # 305 taxa

### Ok. So, now we need to drop (remove) taxa from the tree for which we do not have data

### again, we can do this using a loop and function "dropPaleoTip()":
### ps: there is another (more famous) function called "drop.tip()", which does basically the same,
### however, "dropPaleoTip()" works better on non-ultrametric trees (with fossils)
### because it keeps the ages of the nodes.

for(i in 1: length(five_trees)){five_trees[[i]] <- dropPaleoTip(treeOrig = five_trees[[i]],treeNew = five_trees[[i]]$tip.label[!(five_trees[[i]]$tip.label %in% names(taxon.lengths))])}

### comparing again:
length(my_new_data) # 195 taxa
Ntip(five_trees[[1]]) # 195 taxa

## Now, for the regression analyses, we will also need the "ages data" to contain the
### same number of taxa (195)

### originally, the 'ages" object has more taxa:
str(ages) #305 taxa

### So, let's drop (remove) the other taxa from it:
drop_ages <- ages[(rownames(ages) %in% ttrees[[1]]$tip.label), ]

### Let's compare all three objects:
length(my_new_data) # 195 taxa
Ntip(ttrees[[1]]) # 195 taxa
length(drop_ages$FAD) # 195 taxa

### Finally, let's transform the data back into a "data frame"
my_new_data2 <- data.frame(log_odcl = my_new_data, stringsAsFactors = FALSE)
class(my_new_data2)
str(my_new_data2)
### Dividing taxa into time bins

### In this case, we are using a time_bins file I created in Excel.
### It basically has some arbitrary divisions of time in ~9 million years, and extends back until de the end of the Triassic. In the end, there are 28 time bins

### Read time bins file
timebins <- read.table("time_bins.txt", header=F)

### time range (in binning scheme) of each taxon
taxarange <- binTimeData(drop_ages, int.times=timebins) # this is a function from "paleotree" package

### inspecting:
str(taxarange) # taxa are divided into 28 time bins
taxicDivDisc(taxarange) # this shows the "diversity through time", function of "paleotree" libery, use help to understand

# to know how many taxa (and which are they) for each of the 28 time bins:
taxon.times <- as.data.frame(taxarange$taxon.times)
print(taxon.times)
int.times <- as.data.frame(taxarange$int.times); colnames(int.times) <- c("first.int","last.int")
print(int.times)

### now, let's finally divide them into separate time bins
binned.taxa <- c() # creates an empty list for the loop function
for (i in 1:nrow(int.times)) {binned.taxa[[i]] <- taxon.times[taxon.times$first.int <= i & taxon.times$last.int >= i, ]}
print(binned.taxa[1]) # for taxa in the first (oldest) time bin
### No taxa in this time bin...

binned.taxa[3] #  for taxa in the third time bin 
### 4 taxa in this time bin.

binned.taxa[28] # for taxa in the 28th (earliest) time bin
### many taxa in this time bin!

### Now, let's set trait values (body size values) to each time bin
### body size values for all time bins:
values.all.bins<-c()
for (i in 1:nrow(int.times)) {values.all.bins[[i]] <- list(my_new_data2[rownames(binned.taxa[[i]]), "log_odcl"])}
names(values.all.bins)<-rownames(timebins)
values.all.bins

### For our regression analyses, we will use mean (average) values, let's obtain mean body size values for each time bin.
mean.all.bins<-c()
for (i in 1:nrow(int.times)) {mean.all.bins[[i]] <-mean(my_new_data2[rownames(binned.taxa[[i]]),"log_odcl"])}
names(mean.all.bins)<-rownames(timebins)
mean.all.bins

### Inspect 
head(mean.all.bins)
class(mean.all.bins)
str(mean.all.bins)

###  We could do the same for obtaining maximum, minimum or range values for each time bin it depends on the type of question we want to answer.

### Now, let's include all this information in a data frame (for making analyses easier):
mean_bins <- data.frame("log_odcl" = as.numeric(mean.all.bins), stringsAsFactors = FALSE)
rownames(mean_bins) <- c(28:1)
mean_bins

### visualizing:
plot(rownames(mean_bins), mean_bins$log_odcl, xlim=c(28,0), xlab="time bins", ylab="mean log_odcl", pch=16, col="blue")
### This allowed us to have an idea of the overall pattern of average body size of crocs through time
### pch is a cod of the shape of each point, 17 is triagle, 18 is a losang and 16 is circles

##############################################################################

### Importing abiotic (temperature) data

### The temperature data comes from Prokoph et al. (2008) and is represented by a proxy: delta O18
### the lowest the temperature, the highest the delta O18 value.
### temperature data from Prokoph et al. (2008) is divided into data collected from different latitudes.
### for our analyses, let's use data from temperate latitudes.

### Importing and visualising temperature data:
prokoph_temp <- read.table("Prokoph_temperature_temperate.txt")
### plotting:
plot(prokoph_temp[,1], prokoph_temp[,2],pch=16, col="blue", xlab="time Ma", ylab="d18O", xlim=c(230,0), ylim=c(-8,4))

### The temperature data was already subdivided into time bins
### values are weighted mean values for each time bin
prokoph_temp_binned <- read.table("Prokoph_temperature_bin.txt")
plot(prokoph_temp_binned[,1], prokoph_temp_binned[,2],pch=16, col="red", xlab="time bins", ylab="d18O", xlim=c(28,0), ylim=c(-3.5,1.5))
plot(prokoph_temp_binned[,1], prokoph_temp_binned[,2],pch=16, col="purple", xlab="time bins", ylab="d18O", xlim=c(28,0), ylim=c(-3.5,1), type = "l")

### Now, let's include temperature data into the data frame:
data_size_crocs <- data.frame("Average size" = mean_bins$log_odcl, "Temperature" = temp_temp_binned$V2,
                              "oldest boundary" = int.times$first.int, "earliest boundary" = int.times$last.int)
print(data_size_crocs)
class(data_size_crocs)
str(data_size_crocs) # 28 objects (the )
### note that we don't have temperature data for the first 5 intervals, we will need to remove those first 5 before the regression analyses
### excluding lines (1 to 5) for which we don't have temperature or body size data
data_size_crocs <- data_size_crocs[-c(1:5),] # excludes first 5 lines
length(data_size_crocs[,1]) # 23 time bins

##############################################################################

### Regressions
### First, let's use OLS (the simplest regression), using function "lm()"
### this function uses a formula (y ~ x), where y is the dependent and x is the independent variable
### check the itens in data_size_crocs using $ + tab 1) Avarage.size | 2) Temperature | 3) oldest.boundary | 4) earlist.boundary
ols_model <- lm(data_size_crocs$Average.size ~ data_size_crocs$Temperature)
### let's use function "summary()" for looking into results
summary(ols_model)
head(ols_model)
class(ols_model)
str(ols_model)

### The summary table is important. It has all the information we need to report in publications.
### 1) the p-value: 0.5291. It is not significant | 2) the R squared: -0.02758. It's very weak | 3) value slope: 0.02285 | 4) the intercept: 2.07942
### Now, we can investigate the same relationship, but also incorporating an auto-regressive model,
### For time series analyses.
### We can do this using the "gls()" function, from "nlme" package:
gls_model <- gls(Average.size ~ Temperature, correlation = corARMA(p = 1), data = data_size_crocs, method = "ML")
summary(gls_model)

### let's look at the results 1) p-value: 0.7558. non-significant 2) slope: 0.0119928 3) intercept: 2.0671422

## Note that GLS regressions won't give us the R squared value.

## But it gives us a coefficient that tells us how strong the auto-correlation is:
# Phi: 0.4121824. moderate autoregressive correlation

## this moderate correlation might indicate that the regression with the auto regressive model
# is the best (when compared to the simple OLS model)

## To be sure about that, we need to compare the two models using the AIC scores

## For that, let's use the "gls()" function without any model, to obtain the AIC scores
# this should give us exactly the same results as the "lm()" function:

#the same but using gls() to get AIC (comparative)
ols_gls_model <- gls(Average.size ~ Temperature,
                     data = data_size_crocs, method = "ML")
summary(ols_gls_model)


# Comparing AIC scores:
anova(ols_gls_model,gls_model)


## Indeed, the GLS with the auto-regressive model is "the best" fit (lower AIC score),
# even though both regressions indicated that the relationship between mean size and temperature
# is very weak.
## But the AIC scores allow us to report only the results of the GLS regression...


## Visualizing:
plot(data_size_crocs$Average.size ~ data_size_crocs$Temperature)
abline(ols_gls_model, col = "blue")
abline(gls_model, col = "red")




##############################################################################
##############################################################################
##############################################################################

## Now it's on you!

# Exercise number 1

#  use the same body size and temperature data and run correlation tests (Pearson, Spearman and/or Kendall)


### SOLUTION:

# You can run correlation tests using the function 'cor.test()'
# You can use this function to run all three types of correlation tests (Pearson, Spearman and/or Kendall)
# Let's take a look at the "Help" tab for this function

# It needs x (the independent variable; in this case, the temperature data) and y (the dependent variable; body size)
# It also uses the argument "method", which we can use for choosing between "pearson", "kendall" and "spearman"

# But before we we go ahead and run the tests, let's remember that the "Pearson" test assumes that your data is normally distributed
# To make sure our data follows a normal distribution, we need to test it

# And for testing if a dataset follows a normal distribution, we can use function 'shapiro.test()'

# Let's perform the Shapiro test (normality test) on the body size data:

shapiro.test(data_size_crocs$Average.size)

# The null hypothesis of the Shapiro test is that the data is normally distributed.
# For the body size data, the p-value is 0.04928.
# This means that it rejects the null hypothesis. In other words, the data is NOT normally distributed

# Let's do the same for the temperature data:

shapiro.test(data_size_crocs$Temperature)

# The p-value is 0.6096, so it does not reject the null hypothesis (ie. the data is normally distributed).

# But the Pearson correlation test requires that both variables follow a normal distribution
# So, we should not use Pearson in this case.

# Right, so let's run the tests with "kendall" and "spearman"

test_kendall <- cor.test(data_size_crocs$Temperature, data_size_crocs$Average.size, method = "kendall")

# It worked. Let's look at it:

test_kendall

# p-value is p-value = 0.2483, so it's a non-significant relationship.
# But even if it was significant, the coefficient (tau) of  0.1778656 shows a very week correlation (close to zero)

# Let's do the same with "spearman":

test_spearman <- cor.test(data_size_crocs$Temperature, data_size_crocs$Average.size, method = "spearman")

test_spearman

# As expected, similar results.
# Low correlation coefficient (rho): 0.277668
# And non-significant p-value: 0.1989




##############################################################################
##############################################################################
##############################################################################

## Now, let's use PGLS, which incorporates phylogenetic information

## for that, let's import all the data again


## We will use the following objects (already loaded and checked previously):
dat2
ttrees
dages

# just double-checking if the number of taxa match
length(dat2[,1]) # 195 taxa
Ntip(ttrees[[1]]) # 195 taxa
length(dages$FAD) # 195 taxa


## First, let's import the body size data again:
dat <- read.table("croc_sizes.txt", header=T)

## Now, let's also import a new file, with latitudinal information:

latitude <- read.table("Palaeolatitude.txt", header=T)

## Let's put body size data and latitude in a same file:
ODCL_latitude <- dat
ODCL_latitude[,3] <- latitude$Lat
colnames(ODCL_latitude)[3] <- "Latitude"

ODCL_latitude


## We already have the 5 time-calibrated trees we need:
ttrees

## But, for now, let's select just one tree for PGLS (tree number 1):
pgls_tree <- ttrees[[1]]


#calculating the mean value for multiple specimens
taxon.list <- unique(ODCL_latitude$Taxon)
taxon.lengths<-c()

for(i in 1:length(taxon.list)) {taxon.lengths[i]<-mean(ODCL_latitude[ODCL_latitude$Taxon==taxon.list[i],
                                                                     "log_odcl"])}
names(taxon.lengths)<-taxon.list
log_ODCL<-taxon.lengths


#calculating the mean latitude for multiple specimens
taxon.list.lat <- unique(ODCL_latitude$Taxon)
taxon.lengths.lat<-c()

for(i in 1:length(taxon.list.lat)) {taxon.lengths.lat[i]<-mean(ODCL_latitude[ODCL_latitude$Taxon==taxon.list.lat[i],
                                                                             "Latitude"])}
names(taxon.lengths.lat)<-taxon.list.lat
Lat<-taxon.lengths.lat

## everything in a same data frame again:
ODCL_latitude<-data.frame("Taxon" = names(log_ODCL), "log_ODCL" = unname(log_ODCL, force = F), "Lat" = unname(Lat, force = F))
ODCL_latitude

## Let's plot body size against latitude (to look for any pattern):
plot(ODCL_latitude$log_ODCL ~ ODCL_latitude$Lat)

## It doesn't look very promising...

##############################################################################

## Now, the regressions:

## First, the simple OLS:
ols_model_lat<-lm(log_ODCL ~ Lat, data = ODCL_latitude)
summary(ols_model_lat)

## It shows an almost significant correlation (p-value = 0.05985),
# but weak (R squared = 0.01314)

## Now, the PGLS, that incorporates the phylogeny.
# For that, let's use the "pgls()" function, the "caper" package.
# first, let's put the data in the right format for the function:
ODCL_latitude2 <- comparative.data(pgls_tree, ODCL_latitude, Taxon, vcv=T, vcv.dim=3)

# now, the pgls() function:
pgls_model <- pgls(log_ODCL ~ Lat, ODCL_latitude2, lambda= "ML")
summary(pgls_model)

## This function also gives us a R squared (which can be useful, but problematic)
# in this case, the correlation is significant (p-value = 0.03048),
# but still weak (R squared = 0.01897)

## If we want to compare both regressions, we need, once more, to get the AIC for the OLS using the gls() function:
ols_gls_model_lat<-gls(log_ODCL ~ Lat, data = ODCL_latitude,
                      method = "ML")
sum_ols<-summary(ols_gls_model_lat)

## We cannot use the "anova()" function
# but we can get the AIC scores for both regressions:

## OLS
sum_ols$AIC

## PGLS
pgls_model$aic


## The PGLS fits better our data (lower AIC scores), and we can report the results from this regression only.

## Visualizing:
plot(ODCL_latitude$log_ODCL ~ ODCL_latitude$Lat)
abline(ols_gls_model_lat, col = "blue")
abline(pgls_model, col = "red")





##############################################################################
##############################################################################
##############################################################################

## Now it's on you!

# Exercise number 2

# use data loaded below, evaluate the relationship between ecology (habitat) and body size in croodylomorphs.

#Read the body size data
data_habitats<-read.table("croc_size_habitats.txt",header=T)

# let's quickly look at the data using boxplots
boxplot(log_ODCL ~ Aquaticness, data = data_habitats)

# Aquatic species look larger on average than the other two ecologies/habitats
# But is it significant?

# Investigate this using a phylogenetic ANOVA (there are multiple functions/packages that can do this)


### SOLUTION:


### First, let's import the trees and remove taxa for which we don't have data
# if you already have the trees (or one tree), you don't need to import them and/or remove the taxa)


# loading tree:
trees<-dget(file = "croc tree, 20 trees, mbl method.txt")
# removing taxa:
for (i in 1: length(trees)) {
  trees[[i]] <- dropPaleoTip(trees[[i]],
                             trees[[i]]$tip.label[!(trees[[i]]$tip.label %in% data_habitats$Taxon)])}



# let's select only one tree to make it faster:

tree_number1 <- trees[[1]]


# now, we can run a phylogenetic ANOVA using different functions, from different packages
# the most used is the function 'phylANOVA()' from the package "phytools"

# so, let's load package phytools

library(phytools)


# now, let's try to use function 'phylANOVA()'.
# if you search for this function in the "Help" tab, it will explain what you need.
# first, we need a tree (and we already have it)
# second, we need 'x', which is "a vector containing the group" (this is the "aquaticness" of the species)
# third, we need 'y', which is "a vector containing the response variable" (this is the body size data)
# fourth, we need the number of simulations (nsim), which is usually more than 1000, but we'll use only 100 to make it faster
# fifth, but not mandatory, we can use a method to adjust (ie. correct) the p-value. The "Bonferroni" method good choice.


# Right, let's try!

anova_phy <- phylANOVA(tree_number1, data_habitats$Aquaticness, data_habitats$log_ODCL, nsim = 100, p.adj = "bonferroni")

# It worked, but there were warning messages:
# "Warning: no labels for x. Assuming order of tree$tip.label.
#   Warning: no labels for y. Assuming order of tree$tip.label."

# This warning indicates that there is something wrong with our groups ("aquaticness") and data (body size data)
# Let's take a look at them:

data_habitats$Aquaticness
data_habitats$log_ODCL

# The problem is that they don't show the species/taxa names, so the function don't know how to match these with the species in the tree

# To solve this, we need to add the species names to the groups and data
# We can do this creating new objects for the groups and data
# But another important thing to do is double checking what the documentation of the package says in the "Help" tab
# For both the groups ('x') and data ('y') it says that they have to be a vector
# So, to make sure we are creating vectors, let's use the function 'as.vector()':

groups <- as.vector(data_habitats$Aquaticness)
size_data <- as.vector(data_habitats$log_ODCL)

# Right, now we are sure that these two objects are vectors (as the function requires), but they still don't have the species names
# We know that the first column of the 'data_habitats' object has the species names
# And this first column is called "Taxon". We can check this by running the following:
data_habitats$Taxon

# So, let's add the names (from data_habitats$Taxon) using the function 'names()':
# And we

names(groups) <- data_habitats$Taxon
names(size_data) <- data_habitats$Taxon


# Great! Now it should work:


anova_phy  <- phylANOVA(tree_number1, groups, size_data, nsim = 100, p.adj = "bonferroni")

## IT WORKED!

# let's check the results:
anova_phy # looks like none of the ecological groups are significantly different from one another

######

## There's another option for doing it, which is the function 'lm.rrpp()' from the package "RRPP"
# SO, let's load "RRPP" (if you don't have this package, install it using the "Packages" tab):


library(RRPP)

# First thing, let's take a look at the "Help" tab for the function 'lm.rrpp()'
# It needs a formula and the number of iterations/simulations
# But what is the formula?
# The formula is usually "dependent variable (y) ~ independent variable (x)"
# So, in our case, the formula should be "size_data ~ groups"
# for the number of simulations, let's use 100 again
# finally, this is supposed to be a phylogenetic anova, right?
# But where is the phylogenetic information?
# We need to incorporate the phylogenetic information using argument "Cov", the covariance matrix

# See below

phylo_anova_lm.rrpp  <- lm.rrpp(size_data ~ groups, Cov = vcv.phylo(tree_number1), iter = 100)

# It seems like it worked!
# Let's inspect the results:
phylo_anova_lm.rrpp # Cool, but this is not what we need. Let's try using "summary()"

summary(phylo_anova_lm.rrpp) # still not exactly what we need...

# We need pairwise comparisons, to be sure that the groups are or not significantly different from one another

# so, let's use "summary()" in combination with "pairwise()" (another function from the same package)
summary(pairwise(phylo_anova_lm.rrpp, groups = groups), test.type = "dist", show.vectors = TRUE)


# Well, this shows different results!
# Looks like terrestrial crocs are significantly smaller than both aquatic and semi-aquatic ones
# Function 'lm.rrpp()' uses a different method (permutation procedure) from that of phylANOVA (simulations)
# You can read more about it in

# Adams DC & Collyer ML (2018) Phylogenetic ANOVA: Group-clade aggregation, biological challenges,
# and a refined permutation procedure. Evolution, https://doi.org/10.1111/evo.13492.

# And

# Collyer ML & Adams DC (2018) RRPP: An r package for fitting linear models to high‐dimensional data
# using residual randomization. Methods in Ecology and Evolution, https://doi.org/10.1111/2041-210X.13029.

# That's all folks!
